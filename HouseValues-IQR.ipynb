{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfaa3b285ce4154a",
   "metadata": {},
   "source": [
    "# Harris County Home Price Estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40566c3d40ad1e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:56:30.513512Z",
     "start_time": "2024-11-29T05:56:30.299251Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itables import init_notebook_mode, show\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from load_to_dataframe import load_housing_data, load_mailing_data\n",
    "\n",
    "init_notebook_mode(all_interactive=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9760aa891c253f52",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "In the file **load_to_dataframe.py** there is a function that will load the housing data from the *housing_data.zip* into a data frame. There was some processing of the data so that the CSV would be under 100mb to work with a git repo. Below are the filter that took place. \n",
    "\n",
    "* Only houses with improvement type 1001 (single family homes) will be selected\n",
    "* The date erected must be greater than 1900\n",
    "* The assessed value must be greater than 0\n",
    "* the square footage must be greater than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f76ba3803990e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:56:53.032064Z",
     "start_time": "2024-11-29T05:56:30.572700Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f22859eaf6c6e4",
   "metadata": {},
   "source": [
    "# Haversine Function\n",
    "The haversine function is used to calculate the distance between two sets of latitude and longitude coordinates. In this case one of the fixed points is the center of downtown Houston (29.760100, -95.370100). The assumption is, the closer to Houston's downtown, the higher the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208764c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:10.652618Z",
     "start_time": "2024-11-29T05:56:53.122993Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of Earth in miles\n",
    "    r = 3958.8\n",
    "    # Convert degrees to radians\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    d_phi = np.radians(lat2 - lat1)\n",
    "    d_lambda = np.radians(lon2 - lon1)\n",
    "    # Haversine formula\n",
    "    a = np.sin(d_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(d_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return r * c\n",
    "\n",
    "\n",
    "# Define the single point (latitude, longitude) to calculate the distance from\n",
    "single_point = (29.760100, -95.370100)  # Houston\n",
    "\n",
    "# Add a new column with distances\n",
    "df[\"distance_miles\"] = df.apply(\n",
    "    lambda row: haversine(\n",
    "        single_point[0], single_point[1], row[\"latitude\"], row[\"longitude\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dbd193",
   "metadata": {},
   "source": [
    "# Grouping Account Numbers\n",
    "There are multiple account numbers for properties with multiple buildings, and most of the data is repeated for the different buildings other than the bld_num, date_erected, im_sq_ft, dscr_e, and the perimeter. The rest of the features can have the mean taken and it will be the same number pressent. \n",
    "The dscr_e is an ordial field and the average of the buildings will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ae521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.groupby(\"acct\")\n",
    "    .agg(\n",
    "        bld_num=(\"bld_num\", \"max\"),\n",
    "        date_erected=(\"date_erected\", \"min\"),\n",
    "        im_sq_ft=(\"im_sq_ft\", \"sum\"),\n",
    "        land_ar=(\"land_ar\", \"mean\"),\n",
    "        perimeter=(\"perimeter\", \"sum\"),\n",
    "        bedrooms=(\"bedrooms\", \"mean\"),\n",
    "        full_bath=(\"full_bath\", \"mean\"),\n",
    "        half_bath=(\"half_bath\", \"mean\"),\n",
    "        total_rooms=(\"total_rooms\", \"mean\"),\n",
    "        dscr_e=(\"dscr_e\", \"mean\"),\n",
    "        frame_detached_garage=(\"frame_detached_garage\", \"mean\"),\n",
    "        gunite_pool=(\"gunite_pool\", \"mean\"),\n",
    "        pool_heater=(\"pool_heater\", \"mean\"),\n",
    "        solar_panel=(\"solar_panel\", \"mean\"),\n",
    "        brick_garage=(\"brick_garage\", \"mean\"),\n",
    "        canopy_residential=(\"canopy_residential\", \"mean\"),\n",
    "        frame_abov=(\"frame_abov\", \"mean\"),\n",
    "        frame_shed=(\"frame_shed\", \"mean\"),\n",
    "        carport_residential=(\"carport_residential\", \"mean\"),\n",
    "        foundation_repaired=(\"foundation_repaired\", \"mean\"),\n",
    "        cracked_slab=(\"cracked_slab\", \"mean\"),\n",
    "        latitude=(\"latitude\", \"mean\"),\n",
    "        longitude=(\"longitude\", \"mean\"),\n",
    "        distance_miles=(\"distance_miles\", \"mean\"),\n",
    "        land_val=(\"land_val\", \"mean\"),\n",
    "        bld_val=(\"bld_val\", \"mean\"),\n",
    "        assessed_val=(\"assessed_val\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "df[\"assessed_per_sqft\"] = df[\"assessed_val\"] / df[\"im_sq_ft\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe263ad3029cf8",
   "metadata": {},
   "source": [
    "# Price Per Square Foot\n",
    "This is another metric that I will explore to see if there is a relationship between other values. This data will be cleaned and also a test since any property with 0 square feet will return a divide by zero error, so the row will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae17757-343f-482f-ad5c-dbbbcf6cb0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:10.749921Z",
     "start_time": "2024-11-29T05:57:10.708783Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"assessed_per_sqft\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"assessed_val\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ebadf4831986a",
   "metadata": {},
   "source": [
    "# Reduce data set to a manageable size\n",
    "The current data set is over 1.1M rows. This would take **DAYS** to train a model on a regular computer. This is after the initial filtering when extracting the data from the SQLite database.\n",
    "\n",
    "To reduce the number of houses and remove outliers I will use the inner quartile range to remove the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac90194fc1d0232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:10.767477Z",
     "start_time": "2024-11-29T05:57:10.761806Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"There are {df.shape[0]:,} rows and {df.shape[1]} columns in the df Data Frame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450f66d71cecfc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:11.020271Z",
     "start_time": "2024-11-29T05:57:10.822863Z"
    }
   },
   "outputs": [],
   "source": [
    "# IQR\n",
    "Q1 = df[\"assessed_val\"].quantile(0.25)\n",
    "Q3 = df[\"assessed_val\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_iqr = Q1 - 1.5 * IQR\n",
    "upper_iqr = Q3 + 1.5 * IQR\n",
    "print(f\"Lower IQR: {lower_iqr} | Upper IQR: {upper_iqr}\")\n",
    "\n",
    "df = df[(df[\"assessed_val\"] <= upper_iqr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27842c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"assessed_val\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125dc037",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:11.034654Z",
     "start_time": "2024-11-29T05:57:11.032385Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[\"assessed_val\"]\n",
    "y_per_sqft = df[\"assessed_per_sqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y)\n",
    "plt.xlabel(\"Assessed Values\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Assested Values Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(y_per_sqft)\n",
    "plt.xlabel(\"Price Per Square Foot\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Price Per Square Foot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5d3e6-73d1-45e8-bd54-909de165a040",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Sample Size Reduction\n",
    "Since the data set is still over 1M homes, we need to reduce the size to create a model. I will use 10 thousand random samples from the full data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217ba94-a227-4be6-a384-7136d6c4b0d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:20.482505Z",
     "start_time": "2024-11-29T05:57:20.389527Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=10000, random_state=40)\n",
    "show(sample_df)\n",
    "# sample_df.to_csv(\"sample_housing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb083a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(sample_df[\"assessed_val\"])\n",
    "plt.xlabel(\"Assessed Values\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Assested Values Histogram (Sample Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec9a5fb0afe065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:22.147018Z",
     "start_time": "2024-11-29T05:57:20.511018Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = sample_df.corr()\n",
    "plt.figure(figsize=(25, 12))\n",
    "sns.heatmap(data=corr_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.tight_layout()\n",
    "plt.title(\"Sample Set Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c3bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(sample_df, x=\"im_sq_ft\", y=\"assessed_val\")\n",
    "plt.xlabel(\"Square Footage\")\n",
    "plt.ylabel(\"Assessed Values\")\n",
    "plt.title(\"Square Footage v Assessed Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59960f99",
   "metadata": {},
   "source": [
    "# Create the features as X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef1b57-eb23-4aa8-b5b6-7c4b63bac3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:22.172127Z",
     "start_time": "2024-11-29T05:57:22.167940Z"
    }
   },
   "outputs": [],
   "source": [
    "X = sample_df[\n",
    "    [\n",
    "        \"date_erected\",\n",
    "        \"im_sq_ft\",\n",
    "        \"land_ar\",\n",
    "        \"perimeter\",\n",
    "        \"bedrooms\",\n",
    "        \"full_bath\",\n",
    "        \"half_bath\",\n",
    "        \"total_rooms\",\n",
    "        # \"latitude\",\n",
    "        # \"longitude\",\n",
    "        \"dscr_e\",\n",
    "        \"frame_detached_garage\",\n",
    "        \"gunite_pool\",\n",
    "        \"pool_heater\",\n",
    "        \"brick_garage\",\n",
    "        \"canopy_residential\",\n",
    "        \"frame_abov\",\n",
    "        \"frame_shed\",\n",
    "        \"carport_residential\",\n",
    "        \"foundation_repaired\",\n",
    "        \"cracked_slab\",\n",
    "        \"distance_miles\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "y = sample_df[\"assessed_val\"]\n",
    "print(f\"There are {X.shape[1] + 1} features in total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9b9101-fff1-477e-b001-911f74eb7625",
   "metadata": {},
   "source": [
    "# Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7753a8f-87cd-43d8-94ea-38f00660bddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:22.216451Z",
     "start_time": "2024-11-29T05:57:22.212488Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6da2bf9915a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:57:22.298015Z",
     "start_time": "2024-11-29T05:57:22.260277Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa2050756cb94",
   "metadata": {},
   "source": [
    "# Extra Random Trees\n",
    "Using GridSearchCV for hyperparameter tuning. If this is done, it will increase the model's runtime to take several hours, and depending on the sample size and parameters, the computer may need up to 64 GB of RAM to process the models. If the computer has 32 GB, ensure the n_jobs = 4 or less. If the computer has 16gb of ram put n_jobs=1. n_jobs is the parallel jobs going simultaneously and consuming more resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54fa388ab44d66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:41.725726Z",
     "start_time": "2024-11-29T05:57:22.346262Z"
    }
   },
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [1400, 1500, 1600],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"min_samples_split\": [2, 6],\n",
    "    \"max_features\": [19],\n",
    "    \"criterion\": [\"squared_error\"],\n",
    "    \"warm_start\": [False, True],\n",
    "}\n",
    "etr_cv = GridSearchCV(\n",
    "    etr, param_grid, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "etr_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54cf2a6f2591c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:41.871598Z",
     "start_time": "2024-11-29T07:04:41.867961Z"
    }
   },
   "outputs": [],
   "source": [
    "etr_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde585f13834d255",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:42.027456Z",
     "start_time": "2024-11-29T07:04:42.023479Z"
    }
   },
   "outputs": [],
   "source": [
    "etr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc96f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:42.520885Z",
     "start_time": "2024-11-29T07:04:42.245116Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [f\"{i}\" for i in X.columns]\n",
    "best_model = etr_cv.best_estimator_\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Rank the features by importance\n",
    "importance_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_names, \"Importance\": feature_importances}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Graph the importance of the features\n",
    "importance_df.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\", legend=False)\n",
    "plt.title(\"Feature Importance's\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eae1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:42.670149Z",
     "start_time": "2024-11-29T07:04:42.565372Z"
    }
   },
   "outputs": [],
   "source": [
    "ert_cv_results = pd.DataFrame(etr_cv.cv_results_)\n",
    "ert_cv_results[\"param_n_estimators\"] = ert_cv_results[\"param_n_estimators\"].astype(\n",
    "    \"category\"\n",
    ")\n",
    "ert_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b216a63b",
   "metadata": {},
   "source": [
    "# Savings the model\n",
    "The model will be save to the hard drive so it can be used later without having to run the entire ExtraTreesRegression model again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2af95d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:46.138318Z",
     "start_time": "2024-11-29T07:04:46.076357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the folder name\n",
    "folder_name = \"Models\"\n",
    "\n",
    "# Check if the folder exists, and create it if it doesn't\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Format the date as YYYYmmdd\n",
    "formatted_date = current_date.strftime(\"%Y%m%d\")\n",
    "\n",
    "joblib.dump(etr_cv, f\"Models/etc_{formatted_date}_all_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ac31c",
   "metadata": {},
   "source": [
    "## Analysis of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075f4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:46.029200Z",
     "start_time": "2024-11-29T07:04:46.012219Z"
    }
   },
   "outputs": [],
   "source": [
    "etr_pred = etr_cv.predict(x_test)\n",
    "etr_mae = mean_absolute_error(y_test, etr_pred)\n",
    "etr_mse = mean_squared_error(y_test, etr_pred)\n",
    "etr_r2 = r2_score(y_test, etr_pred)\n",
    "print(f\"MAE: {etr_mae}\\nMSE: {etr_mse}\\nR Squared: {etr_r2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d28ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_test.to_list()\n",
    "predicted = etr_cv.predict(x_test)\n",
    "etc_residuals = pd.DataFrame({\"actual\": actual, \"predicted\": predicted})\n",
    "etc_residuals[\"residuals\"] = etc_residuals[\"actual\"] - etc_residuals[\"predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(etc_residuals, x=\"actual\", y=\"predicted\")\n",
    "plt.xlabel(\"Assessed Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual v Predicted (ERT Regression of Testing Set)\")\n",
    "\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.05,\n",
    "    f\"$R^2 = {etr_r2:.2f}$\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e29776-5ac7-4635-ba1e-c2e55643d653",
   "metadata": {},
   "source": [
    "# Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f155deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = etr_cv.predict(x_train)\n",
    "y_test_pred = etr_cv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08760b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set residuals\n",
    "plt.scatter(y_train_pred, train_residuals)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs. Predicted Values (Train Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_residuals, bins=30, edgecolor=\"k\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Residuals (Train Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe69c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set residuals\n",
    "plt.scatter(y_test_pred, test_residuals)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs. Predicted Values (Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76873fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_residuals, bins=30, edgecolor=\"k\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Residuals (Test Set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(test_residuals)\n",
    "if p > 0.05:\n",
    "    print(f\"Residuals are normally distributed (p > 0.05, p={p}) .\")\n",
    "else:\n",
    "    print(f\"Residuals are not normally distributed (p <= 0.05, p={p}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb20144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(y_test)), test_residuals)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals Plot Across Index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cc207",
   "metadata": {},
   "source": [
    "## Z-Score of the outliers\n",
    "These indexes are results that are stastically different from the models prediction and may need to be indivially reviewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "z_scores = np.abs((test_residuals - np.mean(test_residuals)) / np.std(test_residuals))\n",
    "outliers = np.where(z_scores > 3)\n",
    "print(f\"Outlier indices: {outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba9073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model_ols = sm.OLS(y_train, sm.add_constant(x_train)).fit()\n",
    "influence = model_ols.get_influence()\n",
    "cooks_d = influence.cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862d31e",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regression\n",
    "\n",
    "Gradient boosting is another ensemble algorithm that can be used much like Extra Random Trees. It differs in the way that it makes the trees. In gradient boosting new trees are added to correct errors of the previous tress in a sequential manner, while extra random trees builds tress independently by randomly selecting features and split points at each node, which makes it less prone to overfitting compared to gradient boosting which can be more sensitive to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee27071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:04:47.031760Z",
     "start_time": "2024-11-29T07:04:47.029011Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [4000],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"max_depth\": [5],\n",
    "    \"min_samples_split\": [3],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"max_features\": [10],\n",
    "    \"warm_start\": [True],\n",
    "    \"criterion\": [\"squared_error\"],\n",
    "}\n",
    "gbr_cv = GridSearchCV(\n",
    "    gbr, param_grid, cv=5, n_jobs=-1, scoring=\"neg_mean_squared_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896266f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:21.946164Z",
     "start_time": "2024-11-29T07:04:47.076779Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr_cv.fit(x_train, y_train)\n",
    "gbr_pred = gbr_cv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a1c88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:21.995528Z",
     "start_time": "2024-11-29T07:05:21.991371Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr_mae = mean_absolute_error(y_test, gbr_pred)\n",
    "gbr_mse = mean_squared_error(y_test, gbr_pred)\n",
    "gbr_r2 = r2_score(y_test, gbr_pred)\n",
    "print(f\"MAE: {gbr_mae}\\nMSE: {gbr_mse}\\nR Squared: {gbr_r2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98529ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.051066Z",
     "start_time": "2024-11-29T07:05:22.048004Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434b63e63ea3e08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.318909Z",
     "start_time": "2024-11-29T07:05:22.094358Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = [f\"{i}\" for i in X.columns]\n",
    "best_model = gbr_cv.best_estimator_\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Rank the features by importance\n",
    "importance_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_names, \"Importance\": feature_importances}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Graph the importance of the features\n",
    "importance_df.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\", legend=False)\n",
    "plt.title(\"Feature Importance's\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb55bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.368269Z",
     "start_time": "2024-11-29T07:05:22.365093Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be965b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.582298Z",
     "start_time": "2024-11-29T07:05:22.410691Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(gbr_cv, \"Models/gbr_all_data.pkl\")\n",
    "\n",
    "# load\n",
    "# joblib.load('gbr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fb2d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.631342Z",
     "start_time": "2024-11-29T07:05:22.628483Z"
    }
   },
   "outputs": [],
   "source": [
    "gbr_residual_df = pd.DataFrame(\n",
    "    {\n",
    "        \"actual\": actual,\n",
    "        \"predicted\": gbr_pred,\n",
    "    }\n",
    ")\n",
    "gbr_residual_df[\"residuals\"] = gbr_residual_df[\"actual\"] - gbr_residual_df[\"predicted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ec7dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:22.868965Z",
     "start_time": "2024-11-29T07:05:22.675977Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(gbr_residual_df, x=\"actual\", y=\"predicted\")\n",
    "plt.xlabel(\"Assessed Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual v Predicted (GB Regression)\")\n",
    "\n",
    "plt.text(\n",
    "    0.95,\n",
    "    0.05,\n",
    "    f\"$R^2 = {gbr_r2:.2f}$\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503a929",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:23.044247Z",
     "start_time": "2024-11-29T07:05:22.916949Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(gbr_residual_df, x=\"actual\", y=\"residuals\")\n",
    "plt.xlabel(\"Assessed Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Residuals of Actual v Predicted (GB Regression)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e8fb0b26e968a",
   "metadata": {},
   "source": [
    "# Apply model to entire dataset\n",
    "The model was created with a random subset of the data to reduce the training time. This will apply the model to the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e31394cd6902",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:13.703746Z",
     "start_time": "2024-11-29T07:05:23.366192Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df[\n",
    "    [\n",
    "        \"date_erected\",\n",
    "        \"im_sq_ft\",\n",
    "        \"land_ar\",\n",
    "        \"perimeter\",\n",
    "        \"bedrooms\",\n",
    "        \"full_bath\",\n",
    "        \"half_bath\",\n",
    "        \"total_rooms\",\n",
    "        # \"latitude\",\n",
    "        # \"longitude\",\n",
    "        \"dscr_e\",\n",
    "        \"frame_detached_garage\",\n",
    "        \"gunite_pool\",\n",
    "        \"pool_heater\",\n",
    "        \"brick_garage\",\n",
    "        \"canopy_residential\",\n",
    "        \"frame_abov\",\n",
    "        \"frame_shed\",\n",
    "        \"carport_residential\",\n",
    "        \"foundation_repaired\",\n",
    "        \"cracked_slab\",\n",
    "        \"distance_miles\",\n",
    "    ]\n",
    "]\n",
    "df[\"ert_predicted\"] = etr_cv.predict(X)\n",
    "df[\"gbr_predicted\"] = gbr_cv.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6e8496a5ae291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:13.870227Z",
     "start_time": "2024-11-29T07:06:13.748114Z"
    }
   },
   "outputs": [],
   "source": [
    "df[[\"assessed_val\", \"ert_predicted\", \"gbr_predicted\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b483ac85a248b2c",
   "metadata": {},
   "source": [
    "# Merge Mailing Address\n",
    "Merge the Mailing Address information with the properties to protest.\n",
    "\n",
    "**Need to redo the import of the mailing data from a single file if the database does not exist.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88600f7a460f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:18.371990Z",
     "start_time": "2024-11-29T07:06:13.924759Z"
    }
   },
   "outputs": [],
   "source": [
    "mail_addr = load_mailing_data()\n",
    "df = df.merge(mail_addr, how=\"left\", left_on=\"acct\", right_on=\"acct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d74cf928a0568",
   "metadata": {},
   "source": [
    "# Properties that should be protested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3efaaf87edf525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:18.698247Z",
     "start_time": "2024-11-29T07:06:18.430670Z"
    }
   },
   "outputs": [],
   "source": [
    "protest_ert = df.query(\"assessed_val <= ert_predicted\")\n",
    "protest_gbr = df.query(\"assessed_val <= gbr_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da6437c635e5b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:18.757906Z",
     "start_time": "2024-11-29T07:06:18.754553Z"
    }
   },
   "outputs": [],
   "source": [
    "total = df.shape[0]\n",
    "count_ert = protest_ert.shape[0]\n",
    "count_gbr = protest_gbr.shape[0]\n",
    "print(\n",
    "    f\"Total Accounts: {total}, Extra Trees: {count_ert}, Gradient Boosting Regressor: {count_gbr}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3dfef08cafc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:06:18.878002Z",
     "start_time": "2024-11-29T07:06:18.872762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the folder name\n",
    "folder_name = \"Output\"\n",
    "\n",
    "# Check if the folder exists, and create it if it doesn't\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "\n",
    "def output_dataframe_csv(df_name, name):\n",
    "    df_name.to_csv(f\"Output/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66175651fe61689f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:07:02.611608Z",
     "start_time": "2024-11-29T07:06:18.883317Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dataframe_csv(df, \"All_Data\")\n",
    "output_dataframe_csv(protest_ert, \"Protest_Data_Extra_Trees\")\n",
    "output_dataframe_csv(protest_gbr, \"Protest_Data_Extra_GBR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f52ec506fbd8a",
   "metadata": {},
   "source": [
    "## Proportions of homes to be send advertiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7b61076713202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:07:02.686158Z",
     "start_time": "2024-11-29T07:07:02.682864Z"
    }
   },
   "outputs": [],
   "source": [
    "percent_etr = (count_ert / total) * 100\n",
    "percent_gbr = (count_gbr / total) * 100\n",
    "print(\n",
    "    f\"Extra Random Trees regression model predicts that {percent_etr:.2f}% of total accounts should be protested.\\nGradient Boosting Regressor: {percent_gbr:.2f}% of total accounts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c4726c7901b937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:07:02.829967Z",
     "start_time": "2024-11-29T07:07:02.827797Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
